{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAH5NYgIWIlI"
      },
      "source": [
        "# DiffDock\n",
        "Dock a PDB files and a SMILES with [DiffDock](https://github.com/gcorso/DiffDock).\n",
        "\n",
        "Select Runtime / Run all to run an example PDB file and SMILES.\n",
        "\n",
        "v2 improvements:\n",
        "- works on proteins >1000 aas (with flag added to extract.py)\n",
        "- works on standard GPU (by reducing batch size from 10 to 6)\n",
        "- works with AlphaFold ids (AF-...) as well as PDB ids\n",
        "- works with comma-delimited PDB_ids and/or SMILES\n",
        "- runs smina to generate affinities (as DiffDock posed, or with smina minimization)\n",
        "- shows results in a py3DMol view\n",
        "\n",
        "v3:\n",
        "- fix py3dmol incompatibility\n",
        "- downgrade pytorch since the colab version takes forever to install pytorch_geometric (no binary so it has to compile)\n",
        "\n",
        "v4:\n",
        "- replace smina with the more accurate gnina\n",
        "- remove the annoying run twice thing now there is a binary\n",
        "\n",
        "v5:\n",
        "- add ProLIF fingerprint\n",
        "\n",
        "v6:\n",
        "- bugfixes due to ProLIF version changes. prolif is now locked at 2.0.1\n",
        "\n",
        "colab by [@btnaughton](https://twitter.com/btnaughton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "M4xQfLgqWQsZ"
      },
      "outputs": [],
      "source": [
        "#@title PDB + SMILES input\n",
        "\n",
        "PDB_id = '' #@param {type:\"string\"}\n",
        "SMILES_or_pubchem_id = 'C[C@H]1/C=C/C=C(\\\\C(=O)NC2=CC(=C3C(=C2O)C(=C(C4=C3C(=O)[C@](O4)(O/C=C/[C@@H]([C@H]([C@H]([C@@H]([C@@H]([C@@H]([C@H]1O)C)O)C)OC(=O)C)C)OC)C)C)O)O)/C' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Download a tar file containing all results?\n",
        "download_results = True #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Global variable to store the path of the uploaded file\n",
        "uploaded_pdb_path = None\n",
        "\n",
        "def upload_pdb_file():\n",
        "    \"\"\"Upload PDB file using a widget and save it to a specified directory.\"\"\"\n",
        "    global uploaded_pdb_path\n",
        "\n",
        "    PDB_DIR = \"/tmp/pdb/\"\n",
        "    os.makedirs(PDB_DIR, exist_ok=True)\n",
        "\n",
        "    uploader = widgets.FileUpload(\n",
        "        accept='.pdb',\n",
        "        multiple=False\n",
        "    )\n",
        "    display(uploader)\n",
        "\n",
        "    def on_upload_change(change):\n",
        "        global uploaded_pdb_path\n",
        "        if uploader.value:\n",
        "            uploaded_filename = next(iter(uploader.value))\n",
        "            content = uploader.value[uploaded_filename]['content']\n",
        "            file_path = os.path.join(PDB_DIR, uploaded_filename)\n",
        "            with open(file_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "            uploaded_pdb_path = file_path\n",
        "            print(f\"File uploaded successfully: {file_path}\")\n",
        "\n",
        "    uploader.observe(on_upload_change, names='value')\n",
        "\n",
        "    return uploader\n",
        "\n",
        "# Call the upload function\n",
        "uploader = upload_pdb_file()\n",
        "\n",
        "if uploaded_pdb_path:\n",
        "    pdb_files = [uploaded_pdb_path]\n",
        "    # Process the uploaded PDB file as needed\n",
        "else:\n",
        "    print(\"No PDB file uploaded.\")"
      ],
      "metadata": {
        "id": "Jk64uMxn9sb5",
        "outputId": "ac3ef502-bf42-45a3-9393-b0a977314ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "dedc9be185674a37b6b81565dbe43013",
            "dc51b398b4bf41ea8432fe3826a34c99",
            "89c6748abb5443558d0a9c919bd2195b"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.pdb', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dedc9be185674a37b6b81565dbe43013"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No PDB file uploaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import time\n",
        "from random import random\n",
        "\n",
        "# def download_pdb_file(pdb_id: str) -> str:\n",
        "#     \"\"\"Download pdb file as a string from rcsb.org\"\"\"\n",
        "#     PDB_DIR =\"/tmp/pdb/\"\n",
        "#     os.makedirs(PDB_DIR, exist_ok=True)\n",
        "\n",
        "#     # url or pdb_id\n",
        "#     if pdb_id.startswith('http'):\n",
        "#         url = pdb_id\n",
        "#         filename = url.split('/')[-1]\n",
        "#     elif pdb_id.endswith(\".pdb\"):\n",
        "#         return pdb_id\n",
        "#     else:\n",
        "#         if pdb_id.startswith(\"AF\"):\n",
        "#             url = f\"https://alphafold.ebi.ac.uk/files/{pdb_id}-model_v3.pdb\"\n",
        "#         else:\n",
        "#             url = f\"http://files.rcsb.org/view/{pdb_id}.pdb\"\n",
        "#         filename = f'{pdb_id}.pdb'\n",
        "\n",
        "#     cache_path = os.path.join(PDB_DIR, filename)\n",
        "#     if os.path.exists(cache_path):\n",
        "#         return cache_path\n",
        "\n",
        "#     pdb_req = requests.get(url)\n",
        "#     pdb_req.raise_for_status()\n",
        "#     open(cache_path, 'w').write(pdb_req.text)\n",
        "#     return cache_path\n",
        "\n",
        "def download_smiles_str(pubchem_id: str, retries:int = 2) -> str:\n",
        "    \"\"\"Given a pubchem id, get a smiles string\"\"\"\n",
        "    while True:\n",
        "        req = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/CID/{pubchem_id}/property/CanonicalSMILES/CSV\")\n",
        "        smiles_url_csv = req.text if req.status_code == 200 else None\n",
        "        if smiles_url_csv is not None:\n",
        "            break\n",
        "        if retries == 0:\n",
        "            return None\n",
        "        time.sleep(1+random())\n",
        "        retries -= 1\n",
        "\n",
        "    return smiles_url_csv.splitlines()[1].split(',')[1].strip('\"').strip(\"'\") if smiles_url_csv is not None else None"
      ],
      "metadata": {
        "id": "xnJ7QVsC9yNK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if not PDB_id or not SMILES_or_pubchem_id:\n",
        "#     PDB_id = \"2HV5\"\n",
        "#     SMILES_or_pubchem_id = \"C1=CC(=C(C=C1C2=C(C(=O)C3=C(C=C(C=C3O2)O)O)O)O)O\" # quercetin\n",
        "#     print(f\"No input supplied. Using example data: {PDB_id} and {SMILES_or_pubchem_id}\")\n",
        "\n",
        "# to run many PDB+smiles at once, fill in a list of PDB_files and smiles here...\n",
        "# pdb_files = [download_pdb_file(_PDB_id) for _PDB_id in PDB_id.split(\",\")]\n",
        "pdb_files = [\"/tmp/pdb/STAT3_AlphaFold.pdb\"]\n",
        "smiless = [download_smiles_str(_SMILES_or_pubchem_id) if str(_SMILES_or_pubchem_id).isnumeric() else _SMILES_or_pubchem_id\n",
        "           for _SMILES_or_pubchem_id in SMILES_or_pubchem_id.split(',') ]\n",
        "\n",
        "with open(\"/tmp/input_protein_ligand.csv\", 'w') as out:\n",
        "    out.write(\"protein_path,ligand\\n\")\n",
        "    for pdb_file in pdb_files:\n",
        "        for smiles in smiless:\n",
        "            out.write(f\"{pdb_file},{smiles}\\n\")"
      ],
      "metadata": {
        "id": "203PfV1y91gF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdb_files"
      ],
      "metadata": {
        "id": "_Xqgjxhu9-xn",
        "outputId": "1bc7f20d-b56a-4019-d0b6-804debedbf54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/tmp/pdb/STAT3_AlphaFold.pdb']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ssuid52VT-i"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import requests\n",
        "# import time\n",
        "# from random import random\n",
        "\n",
        "# def download_pdb_file(pdb_id: str) -> str:\n",
        "#     \"\"\"Download pdb file as a string from rcsb.org\"\"\"\n",
        "#     PDB_DIR =\"/tmp/pdb/\"\n",
        "#     os.makedirs(PDB_DIR, exist_ok=True)\n",
        "\n",
        "#     # url or pdb_id\n",
        "#     if pdb_id.startswith('http'):\n",
        "#         url = pdb_id\n",
        "#         filename = url.split('/')[-1]\n",
        "#     elif pdb_id.endswith(\".pdb\"):\n",
        "#         return pdb_id\n",
        "#     else:\n",
        "#         if pdb_id.startswith(\"AF\"):\n",
        "#             url = f\"https://alphafold.ebi.ac.uk/files/{pdb_id}-model_v3.pdb\"\n",
        "#         else:\n",
        "#             url = f\"http://files.rcsb.org/view/{pdb_id}.pdb\"\n",
        "#         filename = f'{pdb_id}.pdb'\n",
        "\n",
        "#     cache_path = os.path.join(PDB_DIR, filename)\n",
        "#     if os.path.exists(cache_path):\n",
        "#         return cache_path\n",
        "\n",
        "#     pdb_req = requests.get(url)\n",
        "#     pdb_req.raise_for_status()\n",
        "#     open(cache_path, 'w').write(pdb_req.text)\n",
        "#     return cache_path\n",
        "\n",
        "# def download_smiles_str(pubchem_id: str, retries:int = 2) -> str:\n",
        "#     \"\"\"Given a pubchem id, get a smiles string\"\"\"\n",
        "#     while True:\n",
        "#         req = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/CID/{pubchem_id}/property/CanonicalSMILES/CSV\")\n",
        "#         smiles_url_csv = req.text if req.status_code == 200 else None\n",
        "#         if smiles_url_csv is not None:\n",
        "#             break\n",
        "#         if retries == 0:\n",
        "#             return None\n",
        "#         time.sleep(1+random())\n",
        "#         retries -= 1\n",
        "\n",
        "#     return smiles_url_csv.splitlines()[1].split(',')[1].strip('\"').strip(\"'\") if smiles_url_csv is not None else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYTBennzXxb1"
      },
      "outputs": [],
      "source": [
        "# if not PDB_id or not SMILES_or_pubchem_id:\n",
        "#     PDB_id = \"6agt\"\n",
        "#     SMILES_or_pubchem_id = \"COc(cc1)ccc1C#N\"\n",
        "#     print(f\"No input supplied. Using example data: {PDB_id} and {SMILES_or_pubchem_id}\")\n",
        "\n",
        "# # to run many PDB+smiles at once, fill in a list of PDB_files and smiles here...\n",
        "# pdb_files = [download_pdb_file(_PDB_id) for _PDB_id in PDB_id.split(\",\")]\n",
        "# smiless = [download_smiles_str(_SMILES_or_pubchem_id) if str(_SMILES_or_pubchem_id).isnumeric() else _SMILES_or_pubchem_id\n",
        "#            for _SMILES_or_pubchem_id in SMILES_or_pubchem_id.split(',') ]\n",
        "\n",
        "# with open(\"/tmp/input_protein_ligand.csv\", 'w') as out:\n",
        "#     out.write(\"protein_path,ligand\\n\")\n",
        "#     for pdb_file in pdb_files:\n",
        "#         for smiles in smiless:\n",
        "#             out.write(f\"{pdb_file},{smiles}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ptul2hJM2HmA"
      },
      "outputs": [],
      "source": [
        "# clear out old results if running multiple times -- hopefully they have been downloaded already\n",
        "!rm -rf /content/DiffDock/results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq9PwzHUWDlj"
      },
      "source": [
        "## Install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FSbikKk6fXAu",
        "outputId": "5982ac17-2a7d-42ff-f340-6b4f744ff0d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htime: 293 µs (started: 2024-10-22 02:05:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime --quiet\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hTQPGM8ptbRy",
        "outputId": "29608634-7eda-46ca-eb5e-6b4881aa19de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'DiffDock'...\n",
            "remote: Enumerating objects: 517, done.\u001b[K\n",
            "remote: Counting objects: 100% (511/511), done.\u001b[K\n",
            "remote: Compressing objects: 100% (318/318), done.\u001b[K\n",
            "remote: Total 517 (delta 244), reused 400 (delta 191), pack-reused 6 (from 1)\u001b[K\n",
            "Receiving objects: 100% (517/517), 233.08 MiB | 47.31 MiB/s, done.\n",
            "Resolving deltas: 100% (244/244), done.\n",
            "/content/DiffDock\n",
            "Note: switching to 'a6c5275'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at a6c5275 remove debugging raise in the inference file\n",
            "time: 10.5 s (started: 2024-10-22 02:05:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"/content/DiffDock\"):\n",
        "    %cd /content\n",
        "    !git clone https://github.com/gcorso/DiffDock.git\n",
        "    %cd /content/DiffDock\n",
        "    !git checkout a6c5275 # remove/update for more up to date code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0vSCAwwrtdr8",
        "outputId": "20596d9c-3626-4bb0-f551-636fb0e64f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pkgtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.16 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.22.4 which is incompatible.\n",
            "albumentations 1.4.15 requires scipy>=1.10.0, but you have scipy 1.7.3 which is incompatible.\n",
            "arviz 0.19.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "arviz 0.19.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
            "astropy 6.1.4 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "bigframes 1.22.0 requires numpy>=1.24.0, but you have numpy 1.22.4 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n",
            "contourpy 1.3.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "jax 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "jaxlib 0.4.33 requires scipy>=1.10, but you have scipy 1.7.3 which is incompatible.\n",
            "mizani 0.11.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.13.6 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.4 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.6.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires networkx>=2.8, but you have networkx 2.6.3 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.19.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "arviz 0.19.0 requires scipy>=1.9.0, but you have scipy 1.7.3 which is incompatible.\n",
            "bigframes 1.22.0 requires numpy>=1.24.0, but you have numpy 1.22.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.22.4 which is incompatible.\n",
            "mizani 0.11.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.13.6 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, but you have scipy 1.7.3 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.22.4 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.13.6 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mtime: 59.7 s (started: 2024-10-22 02:05:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import biopandas\n",
        "except:\n",
        "    !pip install pyg==0.7.1 --quiet\n",
        "    !pip install pyyaml==6.0 --quiet\n",
        "    !pip install scipy==1.7.3 --quiet\n",
        "    !pip install networkx==2.6.3 --quiet\n",
        "    !pip install biopython==1.79 --quiet\n",
        "    !pip install rdkit-pypi==2022.03.5 --quiet\n",
        "    !pip install e3nn==0.5.0 --quiet\n",
        "    !pip install spyrmsd==0.5.2 --quiet\n",
        "    !pip install pandas==1.5.3 --quiet\n",
        "    !pip install biopandas==0.4.1 --quiet\n",
        "    # not diffdock-specific:\n",
        "    !pip install prolif==2.0.1 --quiet # no real version??\n",
        "    !pip install py3dmol==2.0.3 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RZ9qNmHcLMX",
        "outputId": "d9ad94aa-5cf3-4de5-fa9b-12c070192003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n",
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install git+https://github.com/pyg-team/pytorch_geometric.git  --quiet # @ 15573f4674b2a37b1b9adc967df69ef6eee573ea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpIBFqW7eNC7"
      },
      "source": [
        "## Install ESM and prepare PDB file for ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lduAr-WWPyX"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"/content/DiffDock/esm\"):\n",
        "    %cd /content/DiffDock\n",
        "    !git clone https://github.com/facebookresearch/esm\n",
        "    %cd /content/DiffDock/esm\n",
        "    !git checkout ca8a710 # remove/update for more up to date code\n",
        "    !sudo pip install -e .\n",
        "    %cd /content/DiffDock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbxUtRgHwoIx"
      },
      "outputs": [],
      "source": [
        "%cd /content/DiffDock\n",
        "!python datasets/esm_embedding_preparation.py --protein_ligand_csv /tmp/input_protein_ligand.csv --out_file data/prepared_for_esm.fasta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKUU2PKDxTkX"
      },
      "outputs": [],
      "source": [
        "%cd /content/DiffDock\n",
        "%env HOME=esm/model_weights\n",
        "%env PYTHONPATH=$PYTHONPATH:/content/DiffDock/esm\n",
        "!python /content/DiffDock/esm/scripts/extract.py esm2_t33_650M_UR50D data/prepared_for_esm.fasta data/esm2_output --repr_layers 33 --include per_tok --truncation_seq_length 30000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bJTXj5SeYzG"
      },
      "source": [
        "## Run DiffDock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D5gqUcabTAg"
      },
      "outputs": [],
      "source": [
        "%cd /content/DiffDock\n",
        "!python -m inference --protein_ligand_csv /tmp/input_protein_ligand.csv --out_dir results/user_predictions_small --inference_steps 20 --samples_per_complex 40 --batch_size 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlPOKLIBsiPU"
      },
      "source": [
        "# Post-process and download results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqWHbQdeXbe0"
      },
      "outputs": [],
      "source": [
        "%cd /content/DiffDock\n",
        "!wget https://sourceforge.net/projects/smina/files/smina.static/download -O smina && chmod +x smina\n",
        "!wget https://github.com/gnina/gnina/releases/download/v1.0.3/gnina -O gnina && chmod +x gnina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81xcfUI-tU0M"
      },
      "source": [
        "## Run gnina to estimate affinity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpjCe9IWjz5M"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from shlex import quote\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "%cd /content/DiffDock/results/user_predictions_small\n",
        "results_dirs = glob(\"./index*\")\n",
        "\n",
        "rows = []\n",
        "for results_dir in tqdm(results_dirs, desc=\"runs\"):\n",
        "    results_pdb_file = \"/tmp/pdb/\" + re.findall(\"tmp-pdb-(.+\\.pdb)\", results_dir)[0]\n",
        "    results_smiles = re.findall(\"pdb_+(.+)\", results_dir)[0]\n",
        "    results_sdfs = [os.path.join(results_dir, f) for f in os.listdir(results_dir) if \"confidence\" in f and f.endswith(\".sdf\")]\n",
        "\n",
        "    results_pdb_file_no_hetatms = f\"{results_pdb_file}_nohet.pdb\"\n",
        "    !grep -v \"^HETATM\" {results_pdb_file} > {results_pdb_file_no_hetatms}\n",
        "    !cp {results_pdb_file} .\n",
        "\n",
        "    for results_sdf in tqdm(results_sdfs, leave=False, desc=\"files\"):\n",
        "        confidence = re.findall(\"confidence([\\-\\.\\d]+)\\.sdf\", results_sdf)[0]\n",
        "\n",
        "        scored_stdout = !/content/DiffDock/gnina --score_only -r \"{results_pdb_file_no_hetatms}\" -l \"{results_sdf}\"\n",
        "        scored_affinity = re.findall(\"Affinity:\\s*([\\-\\.\\d+]+)\", '\\n'.join(scored_stdout))[0]\n",
        "        minimized_stdout = !/content/DiffDock/gnina --local_only --minimize -r \"{results_pdb_file_no_hetatms}\" -l \"{results_sdf}\" --autobox_ligand \"{results_sdf}\" --autobox_add 2\n",
        "        minimized_affinity = re.findall(\"Affinity:\\s*([\\-\\.\\d+]+)\", '\\n'.join(minimized_stdout))[0]\n",
        "\n",
        "        rows.append((results_pdb_file.split('/')[-1], results_smiles, float(confidence), float(scored_affinity), float(minimized_affinity), results_sdf))\n",
        "\n",
        "df_results = pd.DataFrame(rows, columns=[\"pdb_file\", \"smiles\", \"diffdock_confidence\", \"gnina_scored_affinity\", \"gnina_minimized_affinity\", \"sdf_file\"])\n",
        "df_results_tsv = \"df_diffdock_results.tsv\"\n",
        "df_results.to_csv(df_results_tsv, sep='\\t', index=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ej2vQVtrE9"
      },
      "source": [
        "### Top hit by DiffDock confidence for any PDB/smiles combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw6REL-8s6Ii"
      },
      "outputs": [],
      "source": [
        "top_hit = df_results.sort_values(\"diffdock_confidence\", ascending=False).iloc[0]\n",
        "df_results.sort_values(\"diffdock_confidence\", ascending=False).head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnzZfgTXtbDO"
      },
      "source": [
        "## Show prolif fingerprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCFhotSSsw5o"
      },
      "outputs": [],
      "source": [
        "import prolif as plf\n",
        "from prolif.plotting.network import LigNetwork\n",
        "from rdkit import Chem\n",
        "\n",
        "# load protein\n",
        "prot = Chem.MolFromPDBFile(top_hit.pdb_file, removeHs=False)\n",
        "prot = plf.Molecule(prot)\n",
        "\n",
        "# load ligands\n",
        "lig_suppl = list(plf.sdf_supplier(top_hit.sdf_file))\n",
        "\n",
        "# generate fingerprint\n",
        "fp = plf.Fingerprint()\n",
        "fp.run_from_iterable(lig_suppl, prot)\n",
        "\n",
        "df_prolif = fp.to_dataframe()\n",
        "display(df_prolif)\n",
        "\n",
        "prolif_fingerprint_html = \"prolif_fingerprint.html\"\n",
        "net = LigNetwork.from_fingerprint(fp, lig_suppl[0], kind=\"frame\", frame=0, rotation=0)\n",
        "net.save(prolif_fingerprint_html)\n",
        "net.display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAuG_ORIsssn"
      },
      "source": [
        "## Create dataframe, tar file and download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg4auY_VsqYh"
      },
      "outputs": [],
      "source": [
        "out_pdbs = ' '.join(set(df_results.pdb_file.apply(quote)))\n",
        "out_sdfs = ' '.join(df_results.sdf_file.apply(quote))\n",
        "\n",
        "if download_results:\n",
        "    tarname = f\"diffdock_{datetime.now().isoformat()[2:10].replace('-','')}\"\n",
        "    _ = !tar cvf {tarname}.tar --transform 's,^,{tarname}/,' --transform 's,\\./,,' {out_pdbs} {out_sdfs} {df_results_tsv} {prolif_fingerprint_html}\n",
        "\n",
        "    files.download(f\"{tarname}.tar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIgH3MSt_dWx"
      },
      "source": [
        "## Compare gnina affinities with DiffDock confidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqNY2KK-Xn3t"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "for (pdb_file, smiles), df_group in df_results.groupby([\"pdb_file\", \"smiles\"]):\n",
        "    f, ax = plt.subplots(1, 2, figsize=(20,8))\n",
        "    sns.regplot(data=df_group, x=\"diffdock_confidence\", y=\"gnina_scored_affinity\", ax=ax[0]);\n",
        "    sns.regplot(data=df_group, x=\"diffdock_confidence\", y=\"gnina_minimized_affinity\", ax=ax[1]);\n",
        "\n",
        "    slope, intercept, r_value_scored, p_value, std_err = linregress(df_group[\"diffdock_confidence\"], df_group[\"gnina_scored_affinity\"])\n",
        "    slope, intercept, r_value_minimized, p_value, std_err = linregress(df_group[\"diffdock_confidence\"], df_group[\"gnina_minimized_affinity\"])\n",
        "    ax[0].set_title(f\"{pdb_file} {smiles[:30]} gnina scored r={r_value_scored:.3f}\");\n",
        "    ax[1].set_title(f\"{pdb_file} {smiles[:30]} gnina minimized r={r_value_minimized:.3f}\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbeaGfBEAn3D"
      },
      "source": [
        "# Visualize top hit (highest confidence) in 3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCwsUBpmYof5"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "import py3Dmol\n",
        "\n",
        "resid_hover = \"\"\"\n",
        "function(atom,viewer) {\n",
        "    if(!atom.label) {\n",
        "        atom.label = viewer.addLabel(atom.chain+\" \"+atom.resn+\" \"+atom.resi,\n",
        "            {position: atom, backgroundColor: 'mintcream', fontColor:'black', fontSize:12});\n",
        "    }\n",
        "}\"\"\"\n",
        "unhover_func = \"\"\"\n",
        "function(atom,viewer) {\n",
        "    if(atom.label) {\n",
        "        viewer.removeLabel(atom.label);\n",
        "        delete atom.label;\n",
        "    }\n",
        "}\"\"\"\n",
        "\n",
        "view = py3Dmol.view(width=800, height=800)\n",
        "view.setCameraParameters({'fov': 35, 'z': 100});\n",
        "\n",
        "\n",
        "# add sdf\n",
        "view.addModel(open(top_hit.sdf_file).read(), \"sdf\")\n",
        "view.setStyle({\"model\": 0}, {'stick':{\"color\":\"#ff0000\"}})\n",
        "view.setViewStyle({\"model\": 0}, {'style':'outline','color':'black','width':0.1})\n",
        "view.zoomTo();\n",
        "\n",
        "# add pdb\n",
        "view.addModel(open(top_hit.pdb_file).read(), \"pdb\");\n",
        "view.setStyle({\"model\": 1}, {\"cartoon\":{\"color\":\"spectrum\"}})\n",
        "view.setStyle({\"model\": 1, \"hetflag\":True}, {'stick':{\"color\":\"spectrum\"}})\n",
        "\n",
        "model = view.getModel()\n",
        "model.setHoverable({}, True, resid_hover, unhover_func)\n",
        "\n",
        "view"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dedc9be185674a37b6b81565dbe43013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 0,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".pdb",
            "button_style": "",
            "data": [],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_dc51b398b4bf41ea8432fe3826a34c99",
            "metadata": [],
            "multiple": false,
            "style": "IPY_MODEL_89c6748abb5443558d0a9c919bd2195b"
          }
        },
        "dc51b398b4bf41ea8432fe3826a34c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89c6748abb5443558d0a9c919bd2195b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}